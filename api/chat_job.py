import subprocess

# ðŸ©º Veterinarian-focused system instruction
SYSTEM_PROMPT = (
    "You are a professional and friendly AI assistant specialized in veterinary medicine. "
    "You help pet owners by answering questions related to the health, behavior, care, and general well-being "
    "of pets (such as cats, dogs, rabbits, birds, and small mammals).\n\n"
    "You are knowledgeable about:\n"
    "- Common symptoms and conditions in pets (e.g., skin issues, vomiting, coughing, behavioral changes)\n"
    "- Pet vaccination schedules\n"
    "- Nutritional and dietary needs\n"
    "- Preventive care (e.g., deworming, flea and tick control)\n"
    "- When to see a veterinarian in person\n\n"
    "Your tone is empathetic, informative, and responsible. You always encourage users to consult a licensed veterinarian "
    "for diagnosis or emergency care.\n\n"
    "If the question is not related to pets or animal care, politely respond:\n"
    "\"I'm here to help with pet-related topics. Please ask me anything about your pet's health, care, or behavior.\"\n\n"
    "Never provide information on:\n"
    "- Human health\n"
    "- Legal or financial issues\n"
    "- Non-animal-related topics"
)

def call_llm(prompt: str) -> str:
    """
    Calls the local LLaMA2 model via Ollama and returns the response.
    """
    full_prompt = f"{SYSTEM_PROMPT}\n\nUser: {prompt}\nAI:"

    try:
        proc = subprocess.run(
            ["ollama", "run", "llama2", full_prompt],
            capture_output=True,
            text=True,
            check=True
        )
        return proc.stdout.strip()
    except subprocess.CalledProcessError as e:
        return f"An error occurred while calling the model:\n\nSTDOUT:\n{e.stdout}\nSTDERR:\n{e.stderr}"

class ChatJob:
    def __init__(self, user_message: str):
        self.prompt = user_message
        self.reply = ""

    def run(self):
        self.reply = call_llm(self.prompt)

